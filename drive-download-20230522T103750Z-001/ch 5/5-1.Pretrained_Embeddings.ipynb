{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1bf9cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from annoy import AnnoyIndex\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b67fe4d",
   "metadata": {},
   "source": [
    "사전 훈련된 단어 벡터 사용을 위한 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1de05f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreTrainedEmbeddings(object):\n",
    "    \"\"\" 사전 훈련된 단어 벡터 사용을 위한 래퍼 클래스 \"\"\"\n",
    "    def __init__(self, word_to_index,word_vectors):\n",
    "        \"\"\"\n",
    "        매개변수:\n",
    "            word_to_index (dict): 단어에서 정수로 매핑\n",
    "            word_vectors (numpy 배열의 리스트)\n",
    "        \"\"\"\n",
    "        self.word_to_index = word_to_index\n",
    "        self.word_vectors = word_vectors\n",
    "        self.index_to_word = {v:k for k,v in self.word_to_index.items()}\n",
    "        #dict.items()로 튜플을 받아와서 그 순서를 바꾼 딕셔너리를 생성\n",
    "        \n",
    "        self.index = AnnoyIndex(len(word_vectors[0]),metric = 'euclidean')\n",
    "        print(\"인덱스 만드는 중!\")\n",
    "        for _, i in self.word_to_index.items():\n",
    "            self.index.add_item(i,self.word_vectors[i])\n",
    "        self.index.build(50)\n",
    "        print(\"완료!\")\n",
    "        \n",
    "    @classmethod\n",
    "    def from_embeddings_file(cls, embedding_file):\n",
    "       \n",
    "        \"\"\"사전 훈련된 벡터 파일에서 객체를 만듭니다.\n",
    "        \n",
    "        벡터 파일은 다음과 같은 포맷입니다:\n",
    "            word0 x0_0 x0_1 x0_2 x0_3 ... x0_N\n",
    "            word1 x1_0 x1_1 x1_2 x1_3 ... x1_N\n",
    "        \n",
    "        매개변수:\n",
    "            embedding_file (str): 파일 위치\n",
    "        반환값:\n",
    "            PretrainedEmbeddings의 인스턴스\n",
    "        \"\"\"\n",
    "        word_to_index = {}\n",
    "        word_vectors = []\n",
    "        \n",
    "        \n",
    "         '''\n",
    "        error : cp949' codec can't decode byte 0xe2 in position 5454\n",
    "        \n",
    "        python3 부터는 ANSI 기준으로 작성된 파일만 읽을 수 있다. \n",
    "        UTF-8로 작성된 파일은 보통 방법으로 읽을 때 에러가 난다. \n",
    "\n",
    "        1. utf-8을 붙여준다. \n",
    "        f = open( \"text.txt\", \"r\", \"utf-8\" )\n",
    "\n",
    "        2. 파일의 인코딩을 ANSI로 바꾸면 된다.\n",
    "\n",
    "         '''\n",
    "        with open(embedding_file,encoding='UTF8') as fp:\n",
    "            for line in fp.readlines():\n",
    "                line = line.split(\" \")\n",
    "                word = line[0]\n",
    "                vec = np.array([float(x) for x in line[1:]])\n",
    "                \n",
    "                word_to_index[word] = len(word_to_index)\n",
    "                word_vectors.append(vec)\n",
    "                \n",
    "        return cls(word_to_index, word_vectors)\n",
    "        \n",
    "    def get_embedding(self,word):\n",
    "        \"\"\"\n",
    "        매개변수:\n",
    "            word (str)\n",
    "        반환값\n",
    "            임베딩 (numpy.ndarray) => word에 해당하는 vector 반환\n",
    "        \"\"\"\n",
    "        return self.word_vectors[self.word_to_index[word]]\n",
    "    \n",
    "    def get_closest_to_vector(self,vector,n=1):\n",
    "        \"\"\"벡터가 주어지면 n 개의 최근접 이웃을 반환합니다\n",
    "        매개변수:\n",
    "            vector (np.ndarray): Annoy 인덱스에 있는 벡터의 크기와 같아야 합니다\n",
    "            n (int): 반환될 이웃의 개수\n",
    "        반환값:\n",
    "            [str, str, ...]: 주어진 벡터와 가장 가까운 단어\n",
    "                단어는 거리순으로 정렬되어 있지 않습니다.\n",
    "        \"\"\"\n",
    "        nn_indices = self.index.get_nns_by_vector(vector,n)\n",
    "        return[self.index_to_word[neighbor]for neighbor in nn_indices]\n",
    "    \n",
    "    def compute_and_print_analogy(self,word1,word2,word3):\n",
    "        \"\"\"단어 임베딩을 사용한 유추 결과를 출력합니다\n",
    "\n",
    "        word1이 word2일 때 word3은 __입니다.\n",
    "        이 메서드는 word1 : word2 :: word3 : word4를 출력합니다\n",
    "        \n",
    "        매개변수:\n",
    "            word1 (str)\n",
    "            word2 (str)\n",
    "            word3 (str)\n",
    "        \"\"\"\n",
    "        vec1 = self.get_embedding(word1)\n",
    "        vec2 = self.get_embedding(word2)\n",
    "        vec3 = self.get_embedding(word3)\n",
    "        \n",
    "        #네 번째 단어 임베딩을 계산합니다.\n",
    "        spatial_relationship = vec2 - vec1\n",
    "        vec4 = vec3+spatial_relationship\n",
    "        \n",
    "        closest_words = self.get_closest_to_vector(vec4,n=4)\n",
    "        existing_words = set([word1,word2,word3])\n",
    "        closest_words = [word for word in closest_words if word not in existing_words]\n",
    "        \n",
    "        if len(closest_words) == 0:\n",
    "            print(\"계산된 벡터와 가장 가까운 이웃을 찾을 수 없습니다!\")\n",
    "            return\n",
    "    \n",
    "        for word4 in closest_words:\n",
    "            print(\"{} : {} :: {} : {}\".format(word1,word2,word3,word4))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90318d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인덱스 만드는 중!\n",
      "완료!\n"
     ]
    }
   ],
   "source": [
    "embeddings = PreTrainedEmbeddings.from_embeddings_file('data/glove/glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05a160df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man : he :: woman : she\n",
      "man : he :: woman : her\n"
     ]
    }
   ],
   "source": [
    "embeddings.compute_and_print_analogy('man', 'he', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5228f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fly : plane :: sail : ship\n",
      "fly : plane :: sail : vessel\n"
     ]
    }
   ],
   "source": [
    "embeddings.compute_and_print_analogy('fly','plane','sail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3cff2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man : doctor :: woman : nurse\n",
      "man : doctor :: woman : physician\n",
      "man : doctor :: woman : pregnant\n"
     ]
    }
   ],
   "source": [
    "embeddings.compute_and_print_analogy('man', 'doctor', 'woman')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
